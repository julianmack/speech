{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/julian/STT/awni/speech\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "import speech.loader as loader\n",
    "#import speech.models as models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 2017,\n",
       " 'save_path': 'examples/timit/models/trans_best',\n",
       " 'data': {'train_set': 'examples/timit/data/timit/train.json',\n",
       "  'dev_set': 'examples/timit/data/timit/dev.json',\n",
       "  'start_and_end': False},\n",
       " 'optimizer': {'batch_size': 8,\n",
       "  'epochs': 200,\n",
       "  'learning_rate': 0.001,\n",
       "  'momentum': 0.0},\n",
       " 'model': {'class': 'Transducer',\n",
       "  'dropout': 0.5,\n",
       "  'encoder': {'conv': [[8, 5, 32, 2], [8, 5, 32, 1]],\n",
       "   'rnn': {'dim': 256, 'bidirectional': True, 'layers': 4}},\n",
       "  'decoder': {'embedding_dim': 256, 'layers': 1}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_fp = \"examples/timit/transducer_config.json\"\n",
    "config2 = \"examples/librispeech/config.json\"\n",
    "with open(config_fp, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "with open(config2, \"r\") as f:\n",
    "    config2 = json.load(f)\n",
    "\n",
    "#config[\"data\"]  = config2[\"data\"] #use toy data\n",
    "\n",
    "#print(config2)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 2017,\n",
       " 'save_path': '/home/ubuntu/persistent/experiments/rnnt/baseline/first/',\n",
       " 'data': {'train_set': '/home/ubuntu/Data/LibriSpeech/train-clean-100.json',\n",
       "  'dev_set': '/home/ubuntu/Data/LibriSpeech/dev-clean.json',\n",
       "  'start_and_end': False},\n",
       " 'optimizer': {'batch_size': 8,\n",
       "  'epochs': 200,\n",
       "  'learning_rate': 0.001,\n",
       "  'momentum': 0.0},\n",
       " 'model': {'class': 'Transducer',\n",
       "  'dropout': 0.5,\n",
       "  'encoder': {'conv': [[8, 5, 32, 2], [8, 5, 32, 1]],\n",
       "   'rnn': {'dim': 2048, 'bidirectional': False, 'layers': 4}},\n",
       "  'decoder': {'embedding_dim': 2048, 'layers': 2}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = \"/home/ubuntu/Data/LibriSpeech/train-clean-100.json\"\n",
    "dev_set = \"/home/ubuntu/Data/LibriSpeech/dev-clean.json\"\n",
    "save_path = \"/home/ubuntu/persistent/experiments/rnnt/baseline/first/\"\n",
    "config[\"save_path\"] = save_path\n",
    "config[\"data\"][\"train_set\"] = train_set\n",
    "config[\"data\"][\"dev_set\"] = dev_set\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7d217ec830>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nparams(model):\n",
    "    return sum([p.numel() for p in model.parameters()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model discussion\n",
    "* The implementation combines the joint and prediction networks into the 'decoder' network \n",
    "* SO the ```decoder[\"layers\"]``` is actually the number of layers in the prediction network \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_c =8, h=5, w=32, s=2\n",
      "out_c =8, h=5, w=32, s=1\n",
      "{'conv': [[8, 5, 32, 2], [8, 5, 32, 1]], 'rnn': {'dim': 2048, 'bidirectional': False, 'layers': 4}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'seed': 2017,\n",
       " 'save_path': '/home/ubuntu/persistent/experiments/rnnt/baseline/first/',\n",
       " 'data': {'train_set': '/home/ubuntu/Data/LibriSpeech/train-clean-100.json',\n",
       "  'dev_set': '/home/ubuntu/Data/LibriSpeech/dev-clean.json',\n",
       "  'start_and_end': False},\n",
       " 'optimizer': {'batch_size': 8,\n",
       "  'epochs': 200,\n",
       "  'learning_rate': 0.001,\n",
       "  'momentum': 0.0},\n",
       " 'model': {'class': 'Transducer',\n",
       "  'dropout': 0.5,\n",
       "  'encoder': {'conv': [[8, 5, 32, 2], [8, 5, 32, 1]],\n",
       "   'rnn': {'dim': 2048, 'bidirectional': False, 'layers': 4}},\n",
       "  'decoder': {'embedding_dim': 2048, 'layers': 2}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder definition\n",
    "opt_cfg = config[\"optimizer\"]\n",
    "data_cfg = config[\"data\"]\n",
    "model_cfg = config[\"model\"]\n",
    "\n",
    "enc = model_cfg[\"encoder\"]\n",
    "dec = model_cfg[\"decoder\"]\n",
    "\n",
    "\n",
    "HIDDEN_SIZE = 2048\n",
    "CONV_SIZE = 8 #convolutional channel size\n",
    "BIDIRECTIONAL = False\n",
    "DEC_LAYERS = 2\n",
    "\n",
    "#conv\n",
    "convs = enc[\"conv\"]\n",
    "enc[\"rnn\"][\"dim\"] = HIDDEN_SIZE\n",
    "enc[\"rnn\"][\"bidirectional\"] = BIDIRECTIONAL\n",
    "\n",
    "\n",
    "dec[\"embedding_dim\"] = HIDDEN_SIZE  #NOTE: in strawperson this is 1024. \n",
    "                                    #BUT in awni's implementation we add the encoder and \n",
    "                                    #Prediction network output\n",
    "dec[\"layers\"] = 2\n",
    "\n",
    "\n",
    "out_convs = []\n",
    "for conv in convs:\n",
    "    out_c, h, w, s = conv\n",
    "    out_c = CONV_SIZE\n",
    "    out_convs.append([out_c, h, w, s])\n",
    "\n",
    "enc[\"conv\"] = out_convs\n",
    "\n",
    "for conv in convs:\n",
    "    out_c, h, w, s = conv\n",
    "    print(\"out_c ={}, h={}, w={}, s={}\".format(out_c, h, w, s))\n",
    "print(enc)\n",
    "\n",
    "\n",
    "with open(\"configs/strawperson.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'START_AND_END' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c61964f87b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpreproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_set\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_and_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTART_AND_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'START_AND_END' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#START_AND_END = True #Not sure what this does\n",
    "\n",
    "\n",
    "batch_size = opt_cfg[\"batch_size\"]\n",
    "preproc = loader.Preprocessor(data_cfg[\"train_set\"], start_and_end=START_AND_END)\n",
    "\n",
    "model_class = eval(\"models.\" + model_cfg[\"class\"])\n",
    "model1 = model_class(1024, 26,\n",
    "                        model_cfg)\n",
    "\n",
    "model2 = model_class(1024,1000,\n",
    "                        model_cfg)\n",
    "\n",
    "# train_ldr = loader.make_loader(data_cfg[\"train_set\"],\n",
    "#                     preproc, batch_size)\n",
    "# dev_ldr = loader.make_loader(data_cfg[\"dev_set\"],\n",
    "#                     preproc, batch_size)\n",
    "print(model1)\n",
    "print(nparams(model1))\n",
    "print()\n",
    "\n",
    "print(model2)\n",
    "print(model2.conv)\n",
    "print(nparams(model2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4651307"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model2.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "38 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
